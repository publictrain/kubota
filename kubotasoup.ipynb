{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/publictrain/kubota/blob/main/kubotasoup.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hQAqiNbHDJAn"
      },
      "outputs": [],
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "import requests\n",
        "import time\n",
        "import random\n",
        "import csv\n",
        "import urllib\n",
        "import os\n",
        "import pprint\n",
        "import time\n",
        "import urllib.error\n",
        "import urllib.request\n",
        "\n",
        "# Colabでもどれが使ったライブラリかわかるようにしてくれ\n",
        "\n",
        "headers = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/62.0.3202.94 Safari/537.36\"}\n",
        "\n",
        "def main():\n",
        "  ans_list = []\n",
        "  ans_list_box = []\n",
        "  pdf_list = []\n",
        "  k=int(input(\"(ここに入力した数かける30くらいの安保理データが手に入るよ！\"))\n",
        "\n",
        "  for i in range(122,k):#1ページ目からスタート\n",
        "    load_url = \"https://www.securitycouncilreport.org/un-documents-all-pdfs-last-added/page/{0}\".format(i)# これヘッダーがないと動かない。スクレイピングよけだろう...\n",
        "    html = requests.get(load_url,headers=headers)\n",
        "    soup = BeautifulSoup(html.content, \"html.parser\")\n",
        "    elems = soup.select(\"h7 > a\")# elemsの型はBs特有のもの、h7 > aでネストの探索\n",
        "    for elem in elems:\n",
        "      if \"pdf\" in str(elem).lower():# 議事録のファイル名PVかpvで統制とって国際連合\n",
        "        if \"pv\" in str(elem).lower():# pvからPVが議事録らしい\n",
        "          elem_extract = str(elem.get(\"href\"))# encodeしたままだとSTR型じゃなくてByte型で返してくる\n",
        "          elem_encode = elem_extract.replace(\" \",\"\").encode('ascii', \"ignore\").decode('utf-8')# encode decodeはエラー起きやすい\n",
        "          # print(type(elem_encode))\n",
        "          pdf_list.append(elem_encode)#　elemの型はBs特有のもの、それをキャストしてる\n",
        "    wait_xs()\n",
        "\n",
        "  for p in pdf_list:\n",
        "    print(p)\n",
        "\n",
        "  for j in range(len(pdf_list)):\n",
        "    req = urllib.request.Request(pdf_list[j], headers=headers)# 403よけHeader\n",
        "    download_file(req, \"/content/drive/MyDrive/Colab Notebooks/kubota/gomi2/pekopeko{0}.pdf\".format(j))\n",
        "\n",
        "\n",
        "def wait_xs():\n",
        "  sec = random.uniform(0.1, 0.3)\n",
        "  time.sleep(sec)\n",
        "\n",
        "def download_file(req, dst_path):\n",
        "    try:\n",
        "        with urllib.request.urlopen(req) as web_file:\n",
        "            data = web_file.read()\n",
        "            with open(dst_path, mode='wb') as local_file:\n",
        "                local_file.write(data)\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iJ4R4rHxbJKh"
      },
      "outputs": [],
      "source": [
        "!pip install pdfminer.six"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi\n"
      ],
      "metadata": {
        "id": "9EyH8qkdzuep"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vkbh1V5aY0Z_"
      },
      "outputs": [],
      "source": [
        "from pdfminer.pdfinterp import PDFResourceManager\n",
        "from pdfminer.converter import TextConverter\n",
        "from pdfminer.pdfinterp import PDFPageInterpreter\n",
        "from pdfminer.pdfpage import PDFPage\n",
        "from pdfminer.layout import LAParams\n",
        "from io import StringIO\n",
        "import numpy as np\n",
        "import os\n",
        "import re\n",
        "import csv\n",
        "\n",
        "'''\n",
        "なんでPythonにクラスがあんだよ\n",
        "オブジェクト指向はどうなってんだオブジェクト指向は\n",
        "お前ら禁じられた記法を\n",
        "平気で使ってんじゃねえか\n",
        "分かってんのか！？\n",
        "「シン」が生まれたのは\n",
        "人間が機械に甘えたせいだろうが\n",
        "金取んのかよ！？\n",
        "くそったれ！\n",
        "'''\n",
        "\n",
        "def main():\n",
        "  try:\n",
        "\n",
        "    pekopeko_list = []\n",
        "\n",
        "    # print(dir_num)\n",
        "\n",
        "    # dir_num = 3000\n",
        "\n",
        "    DIR = '/content/drive/MyDrive/Colab Notebooks/kubota/gomi2'\n",
        "    dir_num = sum(os.path.isfile(os.path.join(DIR, name)) for name in os.listdir(DIR))\n",
        "    print(dir_num)\n",
        "    # 1000までは2016までのデータしかないっぽい\n",
        "    # gomi2のpekopeko10を読み込んだときUnexpected EOFが起きる\n",
        "    for i in range(100, 800):\n",
        "      pdf_file_path = \"/content/drive/MyDrive/Colab Notebooks/kubota/gomi2/pekopeko{0}.pdf\".format(i)# これだとpekopeko.pdfが拾えないニョン\n",
        "      is_file = os.path.isfile(pdf_file_path)\n",
        "      if is_file:\n",
        "        print(f\"{pdf_file_path} is a file.\")\n",
        "        with open(pdf_file_path , \"rb\") as pdf_file: #ファイルオブジェクトを受け取り、変数「pdf_file」に代入\n",
        "            output = StringIO() #コンソールに出力されたテキストを取得するため、IOクラス「StringIO」使用\n",
        "            resource_manager = PDFResourceManager()\n",
        "            laparams = LAParams() #レイアウトの変更がなければデフォルトのままで\n",
        "            text_converter = TextConverter(resource_manager, output, laparams=laparams)\n",
        "            page_interpreter = PDFPageInterpreter(resource_manager, text_converter)\n",
        "\n",
        "            for i_page in PDFPage.get_pages(pdf_file): #1ベージずづ処理\n",
        "                page_interpreter.process_page(i_page)\n",
        "\n",
        "            output_text = output.getvalue()\n",
        "            output.close()\n",
        "            text_converter.close()\n",
        "        print(i)\n",
        "        output_nonn_text = output_text.replace('\\n', '').replace(',', '').replace('.', '')\n",
        "        print(output_nonn_text[:200])\n",
        "        pekopeko_list.append(output_nonn_text)\n",
        "      else:\n",
        "        print(\"だめ\")\n",
        "\n",
        "\n",
        "\n",
        "    pekopeko_ok1_list = []\n",
        "    pekopeko_ok2_list = []\n",
        "    pekopeko_ok3_list = []\n",
        "    pekopeko_ok4_list = []\n",
        "    pekopeko_ok5_list = []\n",
        "    pekopeko_ok6_list = []\n",
        "    # print(pekopeko_list)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # 正規表現そのうち使い舞う\n",
        "    for data in pekopeko_list:\n",
        "      if \"2022\" in data[:200] or \"2021\" in data[:200] or \"2020\" in data[:200]  or \"2019\" in data[:200]  or \"2018\" in data[:200]  or \"2017\" in data[:200]  or \"2016\" in data[:200]  or \"2015\" in data[:200]:\n",
        "      # if \"2015\" in data[:200] or \"2014\" in data[:200] or \"2013\" in data[:200] or \"2012\" in data[:200] or \"2011\" in data[:200] or \"2010\" in data[:200]:\n",
        "        # print(type(data))\n",
        "        # f1 = open(\"/content/drive/MyDrive/Colab Notebooks/kubota/gomi/pekopeko1994-1999.csv\", mode=\"w\")\n",
        "        # f2 = open(\"/content/drive/MyDrive/Colab Notebooks/kubota/gomi/pekopeko2000-2004.csv\", mode=\"w\")\n",
        "        # f3 = open(\"/content/drive/MyDrive/Colab Notebooks/kubota/gomi/pekopeko2005-2009.csv\", mode=\"w\")\n",
        "        # f4 = open(\"/content/drive/MyDrive/Colab Notebooks/kubota/gomi/pekopeko2010-2014.csv\", mode=\"w\")\n",
        "        pekopeko_ok1_list.append(data)\n",
        "        # print(\"atarasi\")\n",
        "      elif \"2014\" in data[:200] or \"2013\" in data[:200] or \"2012\" in data[:200]  or \"2011\" in data[:200]  or \"2010\" in data[:200]:\n",
        "        pekopeko_ok2_list.append(data)\n",
        "      elif \"2009\" in data[:200] or \"2008\" in data[:200] or \"2007\" in data[:200]  or \"2006\" in data[:200]  or \"2005\" in data[:200]:\n",
        "        pekopeko_ok3_list.append(data)\n",
        "      elif \"2004\" in data[:200] or \"2003\" in data[:200] or \"2002\" in data[:200]  or \"2001\" in data[:200]  or \"2000\" in data[:200]:\n",
        "        pekopeko_ok4_list.append(data)\n",
        "      elif \"1999\" in data[:200] or \"1998\" in data[:200] or \"1997\" in data[:200]  or \"1996\" in data[:200]  or \"1995\" in data[:200]:\n",
        "        pekopeko_ok5_list.append(data)\n",
        "      else\n",
        "        pekopeko_ok6_list.append(data)\n",
        "\n",
        "    pekopeko_2d1_list =np.array(pekopeko_ok1_list).reshape(-1, 1).tolist()\n",
        "    pekopeko_2d2_list =np.array(pekopeko_ok2_list).reshape(-1, 1).tolist()\n",
        "    pekopeko_2d3_list =np.array(pekopeko_ok3_list).reshape(-1, 1).tolist()\n",
        "    pekopeko_2d4_list =np.array(pekopeko_ok4_list).reshape(-1, 1).tolist()\n",
        "    pekopeko_2d5_list =np.array(pekopeko_ok5_list).reshape(-1, 1).tolist()\n",
        "    pekopeko_2d6_list =np.array(pekopeko_ok6_list).reshape(-1, 1).tolist()\n",
        "\n",
        "\n",
        "    with open('/content/drive/MyDrive/Colab Notebooks/kubota/gomi_dir/pekopeko2015-2022.csv', 'a', newline='') as f:    #newline=''を追加した\n",
        "        writer = csv.writer(f)\n",
        "        writer.writerows(pekopeko_2d1_list)\n",
        "\n",
        "    with open(\"/content/drive/MyDrive/Colab Notebooks/kubota/gomi_dir/pekopeko2010-2014.csv\", 'a', newline='') as f:    #newline=''を追加した\n",
        "        writer = csv.writer(f)\n",
        "        writer.writerows(pekopeko_2d2_list)\n",
        "\n",
        "    with open(\"/content/drive/MyDrive/Colab Notebooks/kubota/gomi_dir/pekopeko2005-2009.csv\", 'a', newline='') as f:    #newline=''を追加した\n",
        "        writer = csv.writer(f)\n",
        "        writer.writerows(pekopeko_2d3_list)\n",
        "\n",
        "    with open(\"/content/drive/MyDrive/Colab Notebooks/kubota/gomi_dir/pekopeko2000-2004.csv\", 'a', newline='') as f:    #newline=''を追加した\n",
        "        writer = csv.writer(f)\n",
        "        writer.writerows(pekopeko_2d4_list)\n",
        "\n",
        "    with open(\"/content/drive/MyDrive/Colab Notebooks/kubota/gomi_dir/pekopeko1994-1999.csv\", 'a', newline='') as f:    #newline=''を追加した\n",
        "        writer = csv.writer(f)\n",
        "        writer.writerows(pekopeko_2d5_list)\n",
        "    with open(\"/content/drive/MyDrive/Colab Notebooks/kubota/gomi_dir/pekopekowakaran.csv\", 'a', newline='') as f:    #newline=''を追加した\n",
        "        writer = csv.writer(f)\n",
        "        writer.writerows(pekopeko_2d6_list)\n",
        "\n",
        "  # ここを二次元配列にしないと行けない気がする\n",
        "  # またあした（ねむい）2022/06/07\n",
        "  # 二週間ぶりで草2022/06/21\n",
        "  except Exception as e:\n",
        "    print(e)\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# こっちは全部のデータ用\n",
        "\n",
        "from pdfminer.pdfinterp import PDFResourceManager\n",
        "from pdfminer.converter import TextConverter\n",
        "from pdfminer.pdfinterp import PDFPageInterpreter\n",
        "from pdfminer.pdfpage import PDFPage\n",
        "from pdfminer.layout import LAParams\n",
        "from io import StringIO\n",
        "import numpy as np\n",
        "import os\n",
        "import re\n",
        "import csv\n",
        "\n",
        "\n",
        "def main():\n",
        "  try:\n",
        "\n",
        "    pekopeko_list = []\n",
        "\n",
        "    # print(dir_num)\n",
        "\n",
        "    # dir_num = 3000\n",
        "\n",
        "    DIR = '/content/drive/MyDrive/Colab Notebooks/kubota/gomi'\n",
        "    dir_num = sum(os.path.isfile(os.path.join(DIR, name)) for name in os.listdir(DIR))\n",
        "    print(dir_num)\n",
        "    # 1000までは2016までのデータしかないっぽい\n",
        "    # gomi2のpekopeko10を読み込んだときUnexpected EOFが起きる\n",
        "    for i in range(200,  1000):\n",
        "      pdf_file_path = \"/content/drive/MyDrive/Colab Notebooks/kubota/gomi/pekopeko{0}.pdf\".format(i)# これだとpekopeko.pdfが拾えないニョン\n",
        "      is_file = os.path.isfile(pdf_file_path)\n",
        "      if is_file:\n",
        "        print(f\"{pdf_file_path} is a file.\")\n",
        "        with open(pdf_file_path , \"rb\") as pdf_file: #ファイルオブジェクトを受け取り、変数「pdf_file」に代入\n",
        "            output = StringIO() #コンソールに出力されたテキストを取得するため、IOクラス「StringIO」使用\n",
        "            resource_manager = PDFResourceManager()\n",
        "            laparams = LAParams() #レイアウトの変更がなければデフォルトのままで\n",
        "            text_converter = TextConverter(resource_manager, output, laparams=laparams)\n",
        "            page_interpreter = PDFPageInterpreter(resource_manager, text_converter)\n",
        "\n",
        "            for i_page in PDFPage.get_pages(pdf_file): #1ベージずづ処理\n",
        "                page_interpreter.process_page(i_page)\n",
        "\n",
        "            output_text = output.getvalue()\n",
        "            output.close()\n",
        "            text_converter.close()\n",
        "        print(i)\n",
        "        output_nonn_text = output_text.replace('\\n', '').replace(',', '').replace('.', '')\n",
        "        print(output_nonn_text[:200])\n",
        "        pekopeko_list.append(output_nonn_text)\n",
        "      else:\n",
        "        print(\"だめ\")\n",
        "    pekopeko_2d_list =np.array(pekopeko_list).reshape(-1, 1).tolist()\n",
        "\n",
        "\n",
        "\n",
        "    with open(\"/content/drive/MyDrive/Colab Notebooks/kubota/gomi_dir/pekopeko_all.csv\", 'a', newline='') as f:\n",
        "      writer = csv.writer(f)\n",
        "      writer.writerows(pekopeko_2d_list)\n",
        "\n",
        "    # ここを二次元配列にしないと行けない気がする\n",
        "    # またあした（ねむい）2022/06/07\n",
        "    # 二週間ぶりで草2022/06/21\n",
        "  except Exception as e:\n",
        "    print(e)\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "_JDAQCbXMTCo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sUsa1v7qtE-8"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "pd.set_option('display.max_rows', 1000)\n",
        "pd.set_option('display.max_columns', 500)\n",
        "pd.set_option(\"display.max_colwidth\", 500)\n",
        "\n",
        "print(\"2015-2022\")\n",
        "df1= pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/kubota/gomi_dir/pekopeko2015-2022.csv\",header=None, encoding=\"utf-8\")\n",
        "print(len(df1))\n",
        "df1_del= df1[~df1.duplicated()]\n",
        "display(df1_del)# 重複した行の削除\n",
        "df1_del.to_csv('/content/drive/MyDrive/Colab Notebooks/kubota/gomi_dir/pekopeko2015-2022.csv')\n",
        "\n",
        "print(\"2010-2014\")\n",
        "\n",
        "df2= pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/kubota/gomi_dir/pekopeko2010-2014.csv\",header=None, encoding=\"utf-8\")\n",
        "print(len(df2))\n",
        "df2_del= df2[~df2.duplicated()]\n",
        "display(df2_del)# 重複した行の削除\n",
        "df2_del.to_csv('/content/drive/MyDrive/Colab Notebooks/kubota/gomi_dir/pekopeko2010-2014.csv')\n",
        "\n",
        "print(\"2005-2009\")\n",
        "df3= pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/kubota/gomi_dir/pekopeko2005-2009.csv\",header=None, encoding=\"utf-8\")\n",
        "print(len(df3))\n",
        "df3_del= df3[~df3.duplicated()]\n",
        "display(df3_del)# 重複した行の削除\n",
        "df3_del.to_csv('/content/drive/MyDrive/Colab Notebooks/kubota/gomi_dir/pekopeko2005-2009.csv')\n",
        "\n",
        "print(\"2000-2004\")\n",
        "df4= pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/kubota/gomi_dir/pekopeko2000-2004.csv\",header=None, encoding=\"utf-8\")\n",
        "df4_del= df4[~df4.duplicated()]\n",
        "display(df4_del)# 重複した行の削除\n",
        "df4_del.to_csv('/content/drive/MyDrive/Colab Notebooks/kubota/gomi_dir/pekopeko2000-2004.csv')\n",
        "\n",
        "print(\"1994-1999\")\n",
        "df5= pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/kubota/gomi_dir/pekopeko1994-1999.csv\",header=None, encoding=\"utf-8\")\n",
        "df5_del= df5[~df5.duplicated()]\n",
        "display(df5_del)# 重複した行の削除\n",
        "df5_del.to_csv('/content/drive/MyDrive/Colab Notebooks/kubota/gomi_dir/pekopeko1994-1999.csv')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#allのやつ\n",
        "import pandas as pd\n",
        "import csv\n",
        "csv.field_size_limit(1000000000)\n",
        "\n",
        "pd.set_option('display.max_rows', 1000)\n",
        "pd.set_option('display.max_columns', 500)\n",
        "pd.set_option(\"display.max_colwidth\", 500)\n",
        "\n",
        "with open(\"/content/drive/MyDrive/Colab Notebooks/kubota/gomi_dir/pekopeko_all.csv\", \"r\", encoding=\"utf-8\", errors=\"\", newline=\"\" ) as f:\n",
        "    lst = csv.reader(f, delimiter=\",\")\n",
        "    df_all = pd.DataFrame(lst)\n",
        "df_all= pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/kubota/gomi_dir/pekopeko_all.csv\",header=None, engine=\"python\",encoding=\"utf-8\")\n",
        "df5_del= df_all[~df_all.duplicated()]\n",
        "display(df5_del)# 重複した行の削除\n",
        "df5_del.to_csv('/content/drive/MyDrive/Colab Notebooks/kubota/gomi_dir/pekopeko_all.csv')"
      ],
      "metadata": {
        "id": "KTxPG-tBUt-o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5LSGKcwTs08d"
      },
      "outputs": [],
      "source": [
        "from gensim.models import word2vec\n",
        "# こっちはcbow\n",
        "# モデル作成\n",
        "# 初期値はsg=0はCBOW\n",
        "corpus = word2vec.Text8Corpus('/content/drive/MyDrive/Colab Notebooks/kubota/gomi_dir/pekopeko2015-2022.csv')  # 形態素分けを下テキストファイル\n",
        "model = word2vec.Word2Vec(corpus, size=200, min_count=1)     # 次元数、とりあえず200次元にする\n",
        "model.save('/content/drive/MyDrive/Colab Notebooks/kubota/gomi_dir/pekopeko2015-2022_model')                        # 保存するモデルの名前\n",
        "\n",
        "corpus = word2vec.Text8Corpus('/content/drive/MyDrive/Colab Notebooks/kubota/gomi_dir/pekopeko2010-2014.csv')  # 形態素分けを下テキストファイル\n",
        "model = word2vec.Word2Vec(corpus, size=200, min_count=1)     # 次元数、とりあえず200次元にする\n",
        "model.save('/content/drive/MyDrive/Colab Notebooks/kubota/gomi_dir/pekopeko2010-2014_model')                        # 保存するモデルの名前\n",
        "\n",
        "corpus = word2vec.Text8Corpus('/content/drive/MyDrive/Colab Notebooks/kubota/gomi_dir/pekopeko2005-2009.csv')  # 形態素分けを下テキストファイル\n",
        "model = word2vec.Word2Vec(corpus, size=200, min_count=1)     # 次元数、とりあえず200次元にする\n",
        "model.save('/content/drive/MyDrive/Colab Notebooks/kubota/gomi_dir/pekopeko2005-2009_model')                        # 保存するモデルの名前\n",
        "\n",
        "corpus = word2vec.Text8Corpus('/content/drive/MyDrive/Colab Notebooks/kubota/gomi_dir/pekopeko2000-2004.csv')  # 形態素分けを下テキストファイル\n",
        "model = word2vec.Word2Vec(corpus, size=200, min_count=1)     # 次元数、とりあえず200次元にする\n",
        "model.save('/content/drive/MyDrive/Colab Notebooks/kubota/gomi_dir/pekopeko2000-2004_model')                        # 保存するモデルの名前\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# これは出現回数を100以上にした、すべてのデータセットを使用した実験\n",
        "# こっちはcbow\n",
        "\n",
        "from gensim.models import word2vec\n",
        "# モデル作成\n",
        "# 初期値はsg=0はCBOW\n",
        "corpus = word2vec.Text8Corpus('/content/drive/MyDrive/Colab Notebooks/kubota/gomi_dir/pekopeko_all.csv')  # 形態素分けを下テキストファイル\n",
        "model = word2vec.Word2Vec(corpus, size=200, min_count=100)     # 次元数、とりあえず200次元にする\n",
        "model.save('/content/drive/MyDrive/Colab Notebooks/kubota/gomi_dir/pekopeko_all_model')"
      ],
      "metadata": {
        "id": "QJYM2taCvWsA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# これは出現回数を100以上にした、すべてのデータセットを使用した実験\n",
        "# こっちはskipgram\n",
        "\n",
        "from gensim.models import word2vec\n",
        "# モデル作成\n",
        "# 初期値はsg=0はCBOW\n",
        "corpus = word2vec.Text8Corpus('/content/drive/MyDrive/Colab Notebooks/kubota/gomi_dir/pekopeko_all.csv')  # 形態素分けを下テキストファイル\n",
        "model = word2vec.Word2Vec(corpus,sg=1 ,size=200, min_count=100)     # 次元数、とりあえず200次元にする\n",
        "model.save('/content/drive/MyDrive/Colab Notebooks/kubota/gomi_dir/spekopeko_all_model')"
      ],
      "metadata": {
        "id": "vqqJQz1FusKD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 単語の出現回数を100回以上に\n",
        "\n",
        "from gensim.models import word2vec\n",
        "# こっちはcbow\n",
        "# モデル作成\n",
        "# 初期値はsg=0はCBOW\n",
        "\n",
        "corpus = word2vec.Text8Corpus('/content/drive/MyDrive/Colab Notebooks/kubota/gomi_dir/pekopeko2015-2022.csv')  # 形態素分けを下テキストファイル\n",
        "model = word2vec.Word2Vec(corpus, size=200, min_count=100)     # 次元数、とりあえず200次元にする\n",
        "model.save('/content/drive/MyDrive/Colab Notebooks/kubota/gomi_dir/100pekopeko2015-2022_model')"
      ],
      "metadata": {
        "id": "cWffiOtVf3bQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import word2vec\n",
        "# こっちはskipgram\n",
        "# モデル作成\n",
        "# 初期値はsg=0はCBOW\n",
        "corpus = word2vec.Text8Corpus('/content/drive/MyDrive/Colab Notebooks/kubota/gomi_dir/pekopeko2015-2022.csv')  # 形態素分けを下テキストファイル\n",
        "model = word2vec.Word2Vec(corpus,sg=1, size=200, min_count=1)     # 次元数、とりあえず200次元にする\n",
        "model.save('/content/drive/MyDrive/Colab Notebooks/kubota/gomi_dir/spekopeko2015-2022_model')                        # 保存するモデルの名前\n",
        "\n",
        "corpus = word2vec.Text8Corpus('/content/drive/MyDrive/Colab Notebooks/kubota/gomi_dir/pekopeko2010-2014.csv')  # 形態素分けを下テキストファイル\n",
        "model = word2vec.Word2Vec(corpus,sg=1, size=200, min_count=1)     # 次元数、とりあえず200次元にする\n",
        "model.save('/content/drive/MyDrive/Colab Notebooks/kubota/gomi_dir/spekopeko2010-2014_model')                        # 保存するモデルの名前\n",
        "\n",
        "corpus = word2vec.Text8Corpus('/content/drive/MyDrive/Colab Notebooks/kubota/gomi_dir/pekopeko2005-2009.csv')  # 形態素分けを下テキストファイル\n",
        "model = word2vec.Word2Vec(corpus,sg=1, size=200, min_count=1)     # 次元数、とりあえず200次元にする\n",
        "model.save('/content/drive/MyDrive/Colab Notebooks/kubota/gomi_dir/spekopeko2005-2009_model')                        # 保存するモデルの名前\n",
        "\n",
        "corpus = word2vec.Text8Corpus('/content/drive/MyDrive/Colab Notebooks/kubota/gomi_dir/pekopeko2000-2004.csv')  # 形態素分けを下テキストファイル\n",
        "model = word2vec.Word2Vec(corpus,sg=1, size=200, min_count=1)     # 次元数、とりあえず200次元にする\n",
        "model.save('/content/drive/MyDrive/Colab Notebooks/kubota/gomi_dir/spekopeko2000-2004_model')                        # 保存するモデルの名前\n"
      ],
      "metadata": {
        "id": "1ksmEkOXOYTK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 単語の出現回数を100回以上に\n",
        "\n",
        "from gensim.models import word2vec\n",
        "# こっちはskipgram\n",
        "# モデル作成\n",
        "# 初期値はsg=0はCBOW\n",
        "\n",
        "corpus = word2vec.Text8Corpus('/content/drive/MyDrive/Colab Notebooks/kubota/gomi_dir/pekopeko2015-2022.csv')  # 形態素分けを下テキストファイル\n",
        "model = word2vec.Word2Vec(corpus,sg=1, size=200, min_count=100)     # 次元数、とりあえず200次元にする\n",
        "model.save('/content/drive/MyDrive/Colab Notebooks/kubota/gomi_dir/100spekopeko2015-2022_model')"
      ],
      "metadata": {
        "id": "uE79JpVunytv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6PJQKkQ54tbt"
      },
      "outputs": [],
      "source": [
        "# こっちはCBOW\n",
        "\n",
        "from gensim.models import word2vec\n",
        "\n",
        "model1 = word2vec.Word2Vec.load('/content/drive/MyDrive/Colab Notebooks/kubota/gomi_dir/pekopeko2015-2022_model') # 先ほど保存したモデル\n",
        "model2 = word2vec.Word2Vec.load('/content/drive/MyDrive/Colab Notebooks/kubota/gomi_dir/pekopeko2010-2014_model') # 先ほど保存したモデル\n",
        "model3 = word2vec.Word2Vec.load('/content/drive/MyDrive/Colab Notebooks/kubota/gomi_dir/pekopeko2005-2009_model') # 先ほど保存したモデル\n",
        "model4 = word2vec.Word2Vec.load('/content/drive/MyDrive/Colab Notebooks/kubota/gomi_dir/pekopeko2000-2004_model') # 先ほど保存したモデル\n",
        "\n",
        "w1 = \"human\"\n",
        "w2 = \"security\"\n",
        "w3 = \"threat\"\n",
        "\n",
        "m1 = model1.wv.similarity(w1, w2)\n",
        "m2 = model2.wv.similarity(w1, w2)\n",
        "m3 = model3.wv.similarity(w1, w2)\n",
        "m4 = model4.wv.similarity(w1, w2)\n",
        "m5 = model1.wv.similarity(w1, w3)\n",
        "m6= model2.wv.similarity(w1, w3)\n",
        "m7 = model3.wv.similarity(w1, w3)\n",
        "m8 = model4.wv.similarity(w1, w3)\n",
        "\n",
        "print(\"2015-2022「\" + w1 + \"」と「\" + w2 + \"」の類似度: \" + str(m1))\n",
        "print(\"2010-2014「\" + w1 + \"」と「\" + w2 + \"」の類似度: \" + str(m2))\n",
        "print(\"2005-2009「\" + w1 + \"」と「\" + w2 + \"」の類似度: \" + str(m3))\n",
        "print(\"2000-2004「\" + w1 + \"」と「\" + w2 + \"」の類似度: \" + str(m4))\n",
        "print(\"-----------------------------------------------------------------------------\")\n",
        "print(\"2015-2022「\" + w1 + \"」と「\" + w3 + \"」の類似度: \" + str(m5))\n",
        "print(\"2010-2014「\" + w1 + \"」と「\" + w3 + \"」の類似度: \" + str(m6))\n",
        "print(\"2005-2009「\" + w1 + \"」と「\" + w3 + \"」の類似度: \" + str(m7))\n",
        "print(\"2000-2004「\" + w1 + \"」と「\" + w3 + \"」の類似度: \" + str(m8))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import word2vec\n",
        "# synonym類義語をCBOWで求める\n",
        "model1 = word2vec.Word2Vec.load('/content/drive/MyDrive/Colab Notebooks/kubota/gomi_dir/pekopeko2015-2022_model') # 先ほど保存したモデル\n",
        "smodel1 =  word2vec.Word2Vec.load('/content/drive/MyDrive/Colab Notebooks/kubota/gomi_dir/spekopeko2015-2022_model') # 先ほど保存したモデル\n",
        "model1100 = word2vec.Word2Vec.load('/content/drive/MyDrive/Colab Notebooks/kubota/gomi_dir/100pekopeko2015-2022_model') # 先ほど保存したモデル\n",
        "smodel1100 = word2vec.Word2Vec.load('/content/drive/MyDrive/Colab Notebooks/kubota/gomi_dir/100spekopeko2015-2022_model') # 先ほど保存したモデル\n",
        "\n",
        "# model2 = word2vec.Word2Vec.load('/content/drive/MyDrive/Colab Notebooks/kubota/gomi_dir/pekopeko2010-2014_model') # 先ほど保存したモデル\n",
        "# model3 = word2vec.Word2Vec.load('/content/drive/MyDrive/Colab Notebooks/kubota/gomi_dir/pekopeko2005-2009_model') # 先ほど保存したモデル\n",
        "# model4 = word2vec.Word2Vec.load('/content/drive/MyDrive/Colab Notebooks/kubota/gomi_dir/pekopeko2000-2004_model') # 先ほど保存したモデル\n",
        "\n",
        "sovereignty = model1.most_similar(\"sovereignty\", topn=20)\n",
        "sovereignty100 = model1100.most_similar(\"sovereignty\", topn=20)\n",
        "\n",
        "\n",
        "print(\"cbow\")\n",
        "for w in sovereignty:\n",
        "  print(w)\n",
        "\n",
        "print(\"cbow100\")\n",
        "for w in sovereignty100:\n",
        "  print(w)\n",
        "\n",
        "ssovereignty = smodel1.most_similar(\"sovereignty\", topn=20)\n",
        "ssovereignty100 = smodel1100.most_similar(\"sovereignty\", topn=20)\n",
        "\n",
        "\n",
        "print(\"skip\")\n",
        "for w in ssovereignty:\n",
        "  print(w)\n",
        "\n",
        "print(\"skip100\")\n",
        "for w in ssovereignty100:\n",
        "  print(w)"
      ],
      "metadata": {
        "id": "vcD0-QBJxqaX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import word2vec\n",
        "\n",
        "model1100 = word2vec.Word2Vec.load('/content/drive/MyDrive/Colab Notebooks/kubota/gomi_dir/pekopeko_all_model') # 先ほど保存したモデル\n",
        "smodel1100 = word2vec.Word2Vec.load('/content/drive/MyDrive/Colab Notebooks/kubota/gomi_dir/spekopeko_all_model') # 先ほど保存したモデル\n",
        "\n",
        "# model2 = word2vec.Word2Vec.load('/content/drive/MyDrive/Colab Notebooks/kubota/gomi_dir/pekopeko2010-2014_model') # 先ほど保存したモデル\n",
        "# model3 = word2vec.Word2Vec.load('/content/drive/MyDrive/Colab Notebooks/kubota/gomi_dir/pekopeko2005-2009_model') # 先ほど保存したモデル\n",
        "# model4 = word2vec.Word2Vec.load('/content/drive/MyDrive/Colab Notebooks/kubota/gomi_dir/pekopeko2000-2004_model') # 先ほど保存したモデル\n",
        "\n",
        "sovereignty100 = model1100.most_similar(\"sovereignty\", topn=20)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(\"cbow100\")\n",
        "for w in sovereignty100:\n",
        "  print(w)\n",
        "\n",
        "ssovereignty100 = smodel1100.most_similar(\"sovereignty\", topn=20)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(\"skip100\")\n",
        "for w in ssovereignty100:\n",
        "  print(w)"
      ],
      "metadata": {
        "id": "LOuoAmPau6Kb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# こっちはSkipgram\n",
        "\n",
        "from gensim.models import word2vec\n",
        "\n",
        "model1 = word2vec.Word2Vec.load('/content/drive/MyDrive/Colab Notebooks/kubota/gomi_dir/spekopeko2015-2022_model') # 先ほど保存したモデル\n",
        "model2 = word2vec.Word2Vec.load('/content/drive/MyDrive/Colab Notebooks/kubota/gomi_dir/spekopeko2010-2014_model') # 先ほど保存したモデル\n",
        "model3 = word2vec.Word2Vec.load('/content/drive/MyDrive/Colab Notebooks/kubota/gomi_dir/spekopeko2005-2009_model') # 先ほど保存したモデル\n",
        "model4 = word2vec.Word2Vec.load('/content/drive/MyDrive/Colab Notebooks/kubota/gomi_dir/spekopeko2000-2004_model') # 先ほど保存したモデル\n",
        "# model5 = word2vec.Word2Vec.load('pekopeko1994-1999_model') # 先ほど保存したモデル\n",
        "\n",
        "\n",
        "# モデル使用\n",
        "# model.wv.most_similar('sovereignty')  # 特定の単語の類似度\n",
        "# model.most_similar('peace')  # 特定の単語の類似度\n",
        "# model.most_similar('security')  # 特定の単語の類似度\n",
        "# model.most_similar('threat')  # 特定の単語の類似度\n",
        "# model.most_similar('africa')  # 特定の単語の類似度\n",
        "\n",
        "\n",
        "# model['America'] # 対象の単語のベクトル配列を見る\n",
        "\n",
        "w1 = \"human\"\n",
        "w2 = \"security\"\n",
        "w3 = \"threat\"\n",
        "\n",
        "\n",
        "m1 = model1.wv.similarity(w1, w2)\n",
        "m2 = model2.wv.similarity(w1, w2)\n",
        "m3 = model3.wv.similarity(w1, w2)\n",
        "m4 = model4.wv.similarity(w1, w2)\n",
        "m5 = model1.wv.similarity(w1, w3)\n",
        "m6= model2.wv.similarity(w1, w3)\n",
        "m7 = model3.wv.similarity(w1, w3)\n",
        "m8 = model4.wv.similarity(w1, w3)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(\"2015-2022「\" + w1 + \"」と「\" + w2 + \"」の類似度: \" + str(m1))\n",
        "print(\"2010-2014「\" + w1 + \"」と「\" + w2 + \"」の類似度: \" + str(m2))\n",
        "print(\"2005-2009「\" + w1 + \"」と「\" + w2 + \"」の類似度: \" + str(m3))\n",
        "print(\"2000-2004「\" + w1 + \"」と「\" + w2 + \"」の類似度: \" + str(m4))\n",
        "print(\"-----------------------------------------------------------------------------\")\n",
        "print(\"2015-2022「\" + w1 + \"」と「\" + w3 + \"」の類似度: \" + str(m5))\n",
        "print(\"2010-2014「\" + w1 + \"」と「\" + w3 + \"」の類似度: \" + str(m6))\n",
        "print(\"2005-2009「\" + w1 + \"」と「\" + w3 + \"」の類似度: \" + str(m7))\n",
        "print(\"2000-2004「\" + w1 + \"」と「\" + w3 + \"」の類似度: \" + str(m8))\n"
      ],
      "metadata": {
        "id": "CtnfrXo8-EaW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def get_df_topn(modelpath, targetword, topn):\n",
        "    \"\"\"Word2Vecのモデルより指定した単語と最も類似度の高い上位n単語をDataFrameに整理して返す.\"\"\"\n",
        "    mw2v = ModelWord2Vec()\n",
        "    mw2v.load(modelpath)\n",
        "    components = mw2v.model.most_similar(targetword, topn=topn)\n",
        "    df = pd.DataFrame()\n",
        "    df[\"rank\"] = [i + 1 for i in range(len(components))]\n",
        "    df[\"word\"] = [component[0] for component in components]\n",
        "    df[\"score\"] = [component[1] for component in components]\n",
        "    return df\n",
        "\n"
      ],
      "metadata": {
        "id": "Z4jUG0RrFK_G"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuClass": "premium",
      "mount_file_id": "1I0GTmUivQQPNrZC7ydaRrJZDEyte6bKL",
      "authorship_tag": "ABX9TyMddL2k/ApZ19NHyMb1YUun",
      "include_colab_link": true
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}